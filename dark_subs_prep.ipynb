{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDH subtitles from https://www.opensubtitles.org/en/ssearch/sublanguageid-ger/idmovie-578221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pysrt #for subs analysis\n",
    "from datetime import date, datetime, timedelta, time\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset is for vocabulary size calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns a dataframe for a given .srt file with text from all the lines\n",
    "def text_from_srt(path):\n",
    "    path = path\n",
    "    pattern = r'\\[(.*?)\\]'\n",
    "    lines=[]\n",
    "    # loading the subs\n",
    "    subs = pysrt.open(path)\n",
    "    #converting to dataframe by combining all lines per episode into one text (without [...] sdh comments | music)\n",
    "    for line in subs:\n",
    "        text = line.text_without_tags.replace('\\n',' ')\n",
    "        # not interested in lyrics and opening text\n",
    "        if '♪' not in text and 'NETFLIX' not in text:\n",
    "            # checking whether it contains sdh comments and removing them\n",
    "            text = re.sub(pattern,'',text)\n",
    "            lines.append(text)\n",
    "        \n",
    "    # concatenating all the values from list to create a text\n",
    "    clean_text = ' '.join(lines)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDH/S03E02.srt\n",
      "S03E02 done, text length:  11089\n",
      "SDH/S01E07.srt\n",
      "S01E07 done, text length:  11794\n",
      "SDH/S01E06.srt\n",
      "S01E06 done, text length:  11988\n",
      "SDH/S03E03.srt\n",
      "S03E03 done, text length:  11569\n",
      "SDH/S03E01.srt\n",
      "S03E01 done, text length:  12846\n",
      "SDH/S01E04.srt\n",
      "S01E04 done, text length:  11558\n",
      "SDH/S01E10.srt\n",
      "S01E10 done, text length:  14168\n",
      "SDH/S01E05.srt\n",
      "S01E05 done, text length:  12000\n",
      "SDH/S03E04.srt\n",
      "S03E04 done, text length:  12915\n",
      "SDH/S01E01.srt\n",
      "S01E01 done, text length:  14919\n",
      "SDH/S03E05.srt\n",
      "S03E05 done, text length:  11043\n",
      "SDH/S03E07.srt\n",
      "S03E07 done, text length:  12737\n",
      "SDH/S01E02.srt\n",
      "S01E02 done, text length:  7375\n",
      "SDH/S01E03.srt\n",
      "S01E03 done, text length:  8602\n",
      "SDH/S03E06.srt\n",
      "S03E06 done, text length:  12883\n",
      "SDH/S02E08.srt\n",
      "S02E08 done, text length:  13514\n",
      "SDH/S02E01.srt\n",
      "S02E01 done, text length:  11861\n",
      "SDH/S02E03.srt\n",
      "S02E03 done, text length:  16212\n",
      "SDH/S02E02.srt\n",
      "S02E02 done, text length:  13237\n",
      "SDH/S02E06.srt\n",
      "S02E06 done, text length:  12861\n",
      "SDH/S02E07.srt\n",
      "S02E07 done, text length:  14415\n",
      "SDH/S02E05.srt\n",
      "S02E05 done, text length:  15437\n",
      "SDH/S02E04.srt\n",
      "S02E04 done, text length:  11181\n",
      "SDH/S03E08.srt\n",
      "S03E08 done, text length:  17130\n",
      "SDH/S01E08.srt\n",
      "S01E08 done, text length:  14477\n",
      "SDH/S01E09.srt\n",
      "S01E09 done, text length:  14593\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_text</th>\n",
       "      <th>episode</th>\n",
       "      <th>season</th>\n",
       "      <th>season00episode00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- -    Zieh dich um.  -Martha? - Das kann nic...</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>S03E02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erinnere mich. Ich erinnere mich an ...</td>\n",
       "      <td>07</td>\n",
       "      <td>01</td>\n",
       "      <td>S01E07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist nicht mehr lustig!  Katharina?  Ulr...</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "      <td>S01E06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Von da an wusste ich, dass sich nichts ände...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>S03E03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wenn wir wüssten, wie die Dinge enden... ......</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "      <td>S03E01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        episode_text episode season  \\\n",
       "0   - -    Zieh dich um.  -Martha? - Das kann nic...      02     03   \n",
       "1        Ich erinnere mich. Ich erinnere mich an ...      07     01   \n",
       "2     Das ist nicht mehr lustig!  Katharina?  Ulr...      06     01   \n",
       "3    \"Von da an wusste ich, dass sich nichts ände...      03     03   \n",
       "4    Wenn wir wüssten, wie die Dinge enden... ......      01     03   \n",
       "\n",
       "  season00episode00  \n",
       "0            S03E02  \n",
       "1            S01E07  \n",
       "2            S01E06  \n",
       "3            S03E03  \n",
       "4            S03E01  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'SDH/'\n",
    "# all .srt files are named like this: S01E01.srt \n",
    "\n",
    "data = pd.DataFrame(columns =[\"episode_text\",\"episode\",\"season\",\"season00episode00\"])\n",
    "i=0\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and '.srt' in filename:\n",
    "        print(f)\n",
    "        i+=1\n",
    "        text = text_from_srt(f)\n",
    "        # appending to a dataframe\n",
    "        data = data.append({\"episode_text\":text,\"episode\":filename[-6:-4],\n",
    "        \"season\":filename[1:3],\"season00episode00\":filename[0:6]},\n",
    "        ignore_index = True)\n",
    "\n",
    "        print(filename[0:6],\"done, text length: \",len(text))\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset is for SDH comments mapping — e.g. we're interested in how often something happens like the music starts playing. This is why we're saving intervals here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mann] Euch geht das am Arsch vorbei! Niemand macht was!\n",
      "clean string:  Euch geht das am Arsch vorbei! Niemand macht was!\n",
      "num of replacements:  1\n"
     ]
    }
   ],
   "source": [
    "# в 10 сабе 2 коммента, в 130 - 1, в 138 - 1 и есть доп текст\n",
    "# print(subs[101].text_without_tags)\n",
    "\n",
    "text = subs[138].text_without_tags.replace('\\n',' ')\n",
    "print(text)\n",
    "\n",
    "pattern = r'\\[(.*?)\\]'\n",
    "\n",
    "# sdh_comments = []\n",
    "# sdh_interval_starts = []\n",
    "matches = re.findall(pattern,text)\n",
    "if len(matches)>0:\n",
    "    # for match in re.findall(pattern,text):\n",
    "    #     print(match)\n",
    "    replacements = re.subn(pattern,'',text)\n",
    "    print(\"clean string: \"+replacements[0])\n",
    "    print(\"num of replacements: \",replacements[1])    \n",
    "    # sdh_comments.append(match)\n",
    "    # sdh_interval_starts.append('time')\n",
    "# sdh_len = len(sdh_comments)\n",
    "\n",
    "\n",
    "\n",
    "# if not text.startswith('♪') and 'NETFLIX' not in text:\n",
    "#     print('not opening or music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third dataset can be created to save lines for intervals like 10 min or 30 min to see the tone dynamic or something. But this is something we'll do later (maybe).\n",
    "\n",
    "Good example can be found here: https://mubaris.com/posts/movie-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading the subtitles\n",
    "# path ='s01/SDH/S01E01.srt'\n",
    "# subs = pysrt.open(path)\n",
    "# print(len(subs))\n",
    "\n",
    "# lines = []\n",
    "# interval_starts = []\n",
    "# for line in subs:\n",
    "#     text = line.text_without_tags.replace('\\n',' ')\n",
    "#     # not interested in lyrics and opening text\n",
    "#     if '♪' not in text and 'NETFLIX' not in text:\n",
    "#         lines.append(text)\n",
    "#         interval_starts.append(line.start.to_time())\n",
    "\n",
    "# sub_len = len(lines)\n",
    "# print(sub_len)\n",
    "\n",
    "# data = pd.DataFrame()\n",
    "# data[\"lines\"] = lines\n",
    "# data[\"interval_starts\"]=interval_starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some silly testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(0, 48, 18, 916000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start = time(0, 0, 0)\n",
    "# end = subs[-1].end.to_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('german')\n",
    "# including Winden as it's just a city name + characters names\n",
    "# stop_words.extend(['Winden','Jonas','Adam','Eva','Hanno','Noah','The Unknown',\\\n",
    "#     'Mikkel','Ines','Michael','Magnus','Bartosz','Egon','Mads','Silja','Agnes',\\\n",
    "#     'Ulrich', 'Katharina','Hannah','Martha','Jana','Tronte',\\\n",
    "#     'Charlotte','Regina','Franziska','Peter','Helge','Aleksander','Boris','Claudia','Elisabeth','Yasin',\\\n",
    "#     'Albers','Kahnwald','Nielsen','Doppler','Tiedemann','Niewald','Tannhaus','Tauber','Wöller','Krüger','Obendorf'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
